for (i in 1:20)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank
max.nindex <- function(m, n=5) {
i <- order(m, decreasing=TRUE)
return(i[1:n])
}
article422908 <- as.matrix(m[422908,])
articlesSimilairesCos <- m %*% t(article422908) / (sqrt(sum(article422908 * article422908)) * sqrt(rowSums(m * m)))
articlesSimilairesCos <- m * t(article422908) / (sqrt(sum(article422908 * article422908)) * sqrt(rowSums(m * m)))
# on affiche les résultats obtenus
max.nindex(articlesSimilairesCos)
articlesSimilairesCor <- cor(t(m), article422908, use='pairwise.complete.obs', method='pearson')
max.nindex(articlesSimilairesCor)
referencesArticle422908 <- article422908
for (k in 1:ncol(referencesArticle422908)){
if (article422908[k]==1) {
referencesArticle422908 <- referencesArticle422908 + m[k,]
}
}
m <- read.table("http://www.groupes.polymtl.ca/log6308/Public/citeseer.rtable")
d <- 0.85
# N <- 1
N <- nrow(m) # nombre d'articles total
# Calcul du nombre de références pour chaque page
nombreReferences <- apply(m,1,sum)
# On assigne 1 à chaque article sans référence pour éviter une division par zéro dans l'algorithme
nombreReferences[nombreReferences == 0] <- 1
# Comme l'algorithme PageRank est récurssif et que deux articles peuvent s'auto-référer on initialise les valeurs PageRank à 1
pageRank <- matrix(1.0, nrow = nrow(m), ncol = ncol(m))
rownames(pageRank) <- rownames(m)
colnames(pageRank) <- colnames(m)
dVector <- rep(d, N)
# Algorithme calculant le pageRank
# Il y a une convergence après x itérations
for (i in 1:20)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank
article422908 <- m["422908",]
articlesRecommandes <- pageRank * article422908
# On trie la liste par ordre décroissant
articlesRecommandes <- sort(articlesRecommandes, decreasing = TRUE)
# On récupère les numéros des articles
head(colnames(articlesRecommandes), 20)
referencesArticle422908 <- article422908
for (k in 1:ncol(referencesArticle422908)){
if (article422908[k]==1) {
referencesArticle422908 <- referencesArticle422908 + m[k,]
}
}
referencesArticle422908[referencesArticle422908 >= 1] <- 1
# On souhaite recommander les articles les plus proche de l'article N°422908 présents dans les références des références à l'article N°422908
newArticlesRecommandes <- pageRank * referencesArticle422908
# On trie la liste par ordre décroissant
newArticlesRecommandes <- sort(newArticlesRecommandes, decreasing = TRUE)
# On récupère les numéros des articles
head(colnames(newArticlesRecommandes), 20)
max.nindex <- function(m, n=5) {
i <- order(m, decreasing=TRUE)
return(i[1:n])
}
article422908 <- as.matrix(m[422908,])
articlesSimilairesCos <- m * t(article422908) / (sqrt(sum(article422908 * article422908)) * sqrt(rowSums(m * m)))
# on affiche les résultats obtenus
max.nindex(articlesSimilairesCos)
articlesSimilairesCor <- cor(t(m), article422908, use='pairwise.complete.obs', method='pearson')
article422908 <- as.matrix(m[422908,])
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2))
(v %*% m)/(n * sqrt(sum(v^2)))
}
# on calcule les similitudes avec la méthode du cosinus
articlesSimilairesCos <- cosinus.vm(article422908, m)
article422908
m[422908,]
m <- read.table("http://www.groupes.polymtl.ca/log6308/Public/citeseer.rtable")
m
m[422908,]
m["422908",]
article422908 <- as.matrix(m["422908",])
article422908
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2))
(v %*% m)/(n * sqrt(sum(v^2)))
}
# on calcule les similitudes avec la méthode du cosinus
articlesSimilairesCos <- cosinus.vm(article422908, m)
max.nindex(articlesSimilairesCos)
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2))
(v * m)/(n * sqrt(sum(v^2)))
}
# on calcule les similitudes avec la méthode du cosinus
articlesSimilairesCos <- cosinus.vm(article422908, m)
#m * t(article422908) / (sqrt(sum(article422908 * article422908)) * sqrt(rowSums(m * m)))
# on affiche les résultats obtenus
max.nindex(articlesSimilairesCos)
articlesSimilairesCor <- cor(article422908, m, use='pairwise.complete.obs', method='pearson')
articlesSimilairesCor <- cor(m, article422908, use='pairwise.complete.obs', method='pearson')
nrow(n)
nrow(m)
nrow(article422908)
ncol(article422908)
ncol(m)
articlesSimilairesCor <- cor(t(m), article422908, use='pairwise.complete.obs', method='pearson')
articlesSimilairesCor <- cor(t(m), article422908, use='pairwise.complete.obs')
articlesSimilairesCor <- cor(t(m), t(article422908), use='pairwise.complete.obs', method='pearson')
articlesSimilairesCor <- cor(m, t(article422908), use='pairwise.complete.obs', method='pearson')
articlesSimilairesCor <- cor(t(article422908), m, use='pairwise.complete.obs', method='pearson')
max.nindex(articlesSimilairesCos)
referencesArticle422908 <- article422908
for (k in 1:ncol(referencesArticle422908)){
if (article422908[k]==1) {
referencesArticle422908 <- referencesArticle422908 + m[k,]
}
}
for (i in 1:15)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank
for (i in 1:10)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank <- matrix(1.0, nrow = nrow(m), ncol = ncol(m))
rownames(pageRank) <- rownames(m)
colnames(pageRank) <- colnames(m)
dVector <- rep(d, N)
# Algorithme calculant le pageRank
# Il y a une convergence après x itérations
# Il faut être patient le for peut prendre du temps
for (i in 1:15)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank
pageRank <- matrix(1.0, nrow = nrow(m), ncol = ncol(m))
rownames(pageRank) <- rownames(m)
colnames(pageRank) <- colnames(m)
dVector <- rep(d, N)
# Algorithme calculant le pageRank
# Il y a une convergence après x itérations
# Il faut être patient le for peut prendre du temps
for (i in 1:10)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank
head(pageRank)
pageRank <- matrix(1.0, nrow = nrow(m), ncol = ncol(m))
pageRank
rownames(pageRank) <- rownames(m)
colnames(pageRank) <- colnames(m)
dVector <- rep(d, N)
# Algorithme calculant le pageRank
# Il y a une convergence après x itérations
# Il faut être patient le for peut prendre du temps
for (i in 1:5)
{
pageRank <- (1 - dVector) / N +   as.matrix(d * t(m)) %*% (pageRank / nombreReferences)
}
pageRank
library(Matrix)
# m : lignes correspondent aux articles - colonnes correspondent aux articles réfèrés
# 1 si l'article ligne i refère à l'article ligne j
# 0 sinon
m <- read.table("http://www.groupes.polymtl.ca/log6308/Public/citeseer.rtable")
cosinus.vm <- function(v,m) {
n <- sqrt(colSums(m^2))
(v %*% m)/(n * sqrt(sum(v^2)))
}
max.nindex <- function(m, n=5) {
i <- order(m, decreasing=TRUE)
return(i[1:n])
}
min.nindex <- function(m, n=5) {
i <- order(m)
return(i[1:n])
}
m.na <- m
m.na[m.na == 0] <- NA
n.voisins <- 20 + 1
distance.article422908 <- sqrt(colSums((m[,"X422908"] - m)^2))
i.distance.article422908 <- min.nindex(distance.article422908, n.voisins)
i.voisins <- i.distance.article422908[names(distance.article422908[i.distance.article422908]) != "X422908"]
wcos.voisins <- cosinus.vm(m[,"X422908"], m[,i.voisins])
dim(m[,"X422908"])
dim(as.matrix(m[,"X422908"]))
wcos.voisins <- cosinus.vm(as.matrix(m[,"X422908"]), m[,i.voisins])
dim(t(m[,"X422908"]))
dim(t(t(m[,"X422908"])))
wcos.voisins <- cosinus.vm(t(t(m[,"X422908"])), m[,i.voisins])
dim(m[,i.voisins])
as.vector(m[,"X422908"])
wcos.voisins <- cosinus.vm(as.vector(m[,"X422908"]), m[,i.voisins])
m[,i.voisins]
as.array(m[,"X422908"])
wcos.voisins <- cosinus.vm(as.array(m[,"X422908"]), m[,i.voisins])
test <- m[,i.voisins]
test
test[test == 0] <- NA
test
wcos.voisins <- cosinus.vm(m[,"X422908"], m[,i.voisins])
wcor <- cor(m[,"X422908"], m[,i.voisins], use='pairwise.complete.obs', method='pearson')
max.nindex(wcor, 6)
wcos.voisins <- cosinus.vm(m[,"X422908"], test)#m[,i.voisins]
test
wcor <- cor(m[,"X422908"], m[,i.voisins], use='pairwise.complete.obs', method='pearson')
max.nindex(wcor, 6)
mX422908 <- m[,"X422908"]
mX422908
mX422908[1]
library(Matrix)
# m : lignes correspondent aux articles - colonnes correspondent aux articles réfèrés
# 1 si l'article ligne i refère à l'article ligne j
# 0 sinon
m <- read.table("http://www.groupes.polymtl.ca/log6308/Public/citeseer.rtable")
max.nindex <- function(m, n=20) {
i <- m[order(-m), ,drop = FALSE]
i <- rownames(i)
return(i[1:n])
}
# Itemisation
i422908.q2 <- as.matrix((m["422908",]))
m.q2 <- as.matrix(m)
# Application du cosinus et renvoi des 20 premiers r?sultats
i422908.cos <- (m.q2 %*% t(i422908.q2)) / sqrt(sum(i422908.q2^2)) / sqrt(rowSums(m.q2^2))
resultat.cos <- max.nindex(i422908.cos)
resultat.cos
i422908 <- as.matrix((m["422908",]))
matrice <- as.matrix(m)
# Application du cosinus et renvoi des 20 premiers r?sultats
i422908.cos <- (matrice %*% t(i422908)) / sqrt(sum(i422908^2)) / sqrt(rowSums(matrice^2))
resultat.cos <- max.nindex(i422908.cos)
max.nindex(i422908.cos)
library(Matrix)
m <- read.table("http://www.groupes.polymtl.ca/log6308/Public/citeseer.rtable")
d <- 0.85
# nombre d'articles total
N <- nrow(m)
# Calcul du nombre de réfèrences sortantes pour chaque page
s <- apply(m,1,sum)
# On remplace les 0 par des 1 pour éviter une divisions par zéro dans l'algorithme
# Ces valeurs ne seront de toutes façons pas considérées puisque les D_i réfèrent A et ont donc au moins une référence
s[s==0] <- 1
# Comme l'algorithme PageRank est récurssif et que deux articles peuvent s'auto-référer on initialise les valeurs PageRank à 1
r <- numeric(N) + 1
# Vecteur d'amortissement
dVector <- rep(d, N)
# matrice d'adjacence
A <- t(m)
# Algorithme calculant le pageRank en matriciel : r = (1 - dVector) / N + d * A %*% (r/s)
pageRank <- function(r, A, s, N, d, dVector) {
res <- (1 - dVector) / N + d * A %*% (r / s)
# Si on a convergé, on retourne le pageRank
if(all(res == r)) {
return(res);
}
# Sinon on calcule recursivement
return(pageRank(res, A, s, N, d, dVector))
}
# On calcule le pageRank pour tous les articles
pr <- pageRank(r, A, s, N, d, dVector)
# On récupèe l'article 422908
article422908 <- m["422908",]
# Il y a 17 articles référés par 422908
sum(article422908)
# On va d'abord recommander les 5 articles ayant le meilleur pagerank parmis les recommandation de 422908
# On récupère uniquement les pageRank des articles référés par 422908
articlesRecommandes <- pr * article422908
# On trie la liste par ordre décroissant
articlesRecommandes <- sort(articlesRecommandes, decreasing = TRUE)
# On récupère les numéros des 5 articles recommandés et on les affiche
head(colnames(articlesRecommandes), 5)
# Autre approche : on cherche toutes les références des références
# On calcule le vecteurs regroupant toutes les références
referencesArticle422908 <- article422908
for (k in 1:ncol(referencesArticle422908)){
# si k est référencé par 422908
if (article422908[k]==1) {
# ici on ajoute les références de l'article k
referencesArticle422908 <- referencesArticle422908 + m[k,]
}
}
# Comme on a sommé précédemment les références, on s'assure qu'il n'y a que des 1 et des 0
referencesArticle422908[referencesArticle422908 >= 1] <- 1
# On souhaite recommander les articles les plus proche de l'article N°422908 présents dans les références des références à l'article N°422908
newArticlesRecommandes <- pr * referencesArticle422908
# On trie la liste par ordre décroissant
newArticlesRecommandes <- sort(newArticlesRecommandes, decreasing = TRUE)
# On récupère les numéros des articles
head(colnames(newArticlesRecommandes), 5)
max.nindex <- function(m, n=20) {
i <- m[order(-m), ,drop = FALSE]
i <- rownames(i)
return(i[1:n])
}
i422908 <- as.matrix((m["422908",]))
matrice <- as.matrix(m)
# Application du cosinus et renvoie des 20 premiers résultats
i422908.cos <- (matrice %*% t(i422908)) / sqrt(sum(i422908^2)) / sqrt(rowSums(matrice^2))
max.nindex(i422908.cos)
library(Matrix)
setwd('/Applications/XCodeProjects/RecommendingWeb/DataCreator') # à modifier selon la machine
u.data <- read.csv(file='data.csv', sep=',', header=T)
i.data <- read.csv(file='item.csv', sep=',', header=T)
head(i.data)
i.data
i.data <- read.csv(file='item.csv', sep=',', header=T)
i.data
head(u.data)
u.data
head(u.data)
u.data <- read.csv(file='data.csv', sep=',', header=T)
i.data <- read.csv(file='item.csv', sep=',', header=T)
u.data
u.data <- read.csv(file='data_test.csv', sep=',', header=T)
u.data
u.data <- read.csv(file='data.csv', sep=',', header=T)
u.data
u.data <- read.csv(file='data.csv', sep=',', header=T)
u.data
u.data <- read.csv(file='data.csv', sep=',', header=T)
u.data
i.data <- read.csv(file='item.csv', sep=',', header=T)
u.data <- read.csv(file='data.csv', sep=',', header=T)
u.data
u.data <- read.csv(file='data.csv', sep=',', header=T)
u.data
nrow(u.data)
u.data[10000,]
u.data[14000,]
u.data[14100,]
u.data[14150,]
u.data[14140,]
u.data[14141,]
u.data[14142,]
user.id <- 1
# TimeSolt : 0h-5h ; 5h-9h ; 9h-12h ; 12h-14h ; 14h-19h ; 19h-24h
hour <- 10
# Day : Lundi = 1 ; Mardi = 2 ; Mercredi = 3 ; Jeudi = 4 ; Vendredi = 5 ; Samedi = 6 ; Dimanche = 7
day <- 1
latitude <- 45.505
longitude <- -73.613
getTimeSoltHourMin <- function(h) {
if (h < 5) {
return(0)
} else if (h < 9) {
return(5)
} else if (h < 12) {
return(9)
} else if (h < 14) {
return(12)
} else if (h < 19) {
return(14)
}
return(19)
}
getTimeSoltHourMax <- function(h) {
if (h < 5) {
return(5)
} else if (h < 9) {
return(9)
} else if (h < 12) {
return(12)
} else if (h < 14) {
return(14)
} else if (h < 19) {
return(19)
}
return(24)
}
getPreviousDay <- function(d) {
if (d == 1) {
return(7)
}
return(d-1)
}
getNextDay <- function(d) {
if (d == 7) {
return(1)
}
return(d+1)
}
getPreviousTimeSolt <- function(d, hourMin) {
if (hourMin < 5) {
return(c(getPreviousDay(d),19,24))
} else if (hourMin < 9) {
return(c(d,0,5))
} else if (hourMin < 12) {
return(c(d,5,9))
} else if (hourMin < 14) {
return(c(d,9,12))
} else if (hourMin < 19) {
return(c(d,12,14))
}
return(c(d,14,19))
}
getNextTimeSolt <- function(d, hourMin, hourMax) {
if (hourMin < 5) {
return(c(d,5,9))
} else if (hourMin < 9) {
return(c(d,9,12))
} else if (hourMin < 12) {
return(c(d,12,14))
} else if (hourMin < 14) {
return(c(d,14,19))
} else if (hourMin < 19) {
return(c(d,19,24))
}
return(c(getNextDay(d),0,5))
}
getLazyRecommandations <- function(id, timeSolt.hourMin, timeSolt.hourMax, d, coeff) {
recommandations <- u.data[u.data$user_id == id,]
recommandations <- recommandations[recommandations$day == d,]
recommandations <- recommandations[recommandations$hour < timeSolt.hourMax,]
recommandations <- recommandations[recommandations$hour >= timeSolt.hourMin,]
webSite.id <- unique(recommandations$webSite_id)
webSite.time <- webSite.id
for (i in 1:length(webSite.id)) {
webSite.time[i] <- sum(recommandations[recommandations$webSite_id == webSite.id[i],]$time) * coeff
}
resultat <- matrix(NA, nrow = length(webSite.id), ncol = 2)
resultat[,1] <- webSite.id
resultat[,2] <- webSite.time
return(resultat)
}
getRecommandationsForLocalization <- function(longitude, latitude, id) {
recommandations <- u.data[u.data$user_id == id,]
recommandations <- recommandations[recommandations$latitude == latitude,]
recommandations <- recommandations[recommandations$longitude == longitude,]
webSite.id <- unique(recommandations$webSite_id)
webSite.time <- webSite.id
for (i in 1:length(webSite.id)) {
webSite.time[i] <- sum(recommandations[recommandations$webSite_id == webSite.id[i],]$time) * 2.0
}
resultat <- matrix(NA, nrow = length(webSite.id), ncol = 2)
resultat[,1] <- webSite.id
resultat[,2] <- webSite.time
return(resultat)
}
mergeRecommandations <- function(matrice, m) {
if (nrow(m) <= 0) {
return(matrice)
}
for (i in 1:nrow(m)) {
ok <- FALSE
if (nrow(matrice) > 0) {
for (j in 1:nrow(matrice)) {
if (m[i,1] == matrice[j,1]) {
matrice[j,2] <- matrice[j,2] + m[i,2]
ok <- TRUE
break
}
}
}
if (!ok) {
matrice <- rbind(matrice, m[i,])
}
}
return(matrice)
}
getRecommandations <- function(id, h, d) {
coeff <- 1.0
timeSolt.hourMin <- getTimeSoltHourMin(h)
timeSolt.hourMax <- getTimeSoltHourMax(h)
recommandations <- u.data[u.data$user_id == id,]
recommandations <- recommandations[recommandations$day == d,]
recommandations <- recommandations[recommandations$hour < timeSolt.hourMax,]
recommandations <- recommandations[recommandations$hour >= timeSolt.hourMin,]
webSite.id <- unique(recommandations$webSite_id)
webSite.time <- webSite.id
for (i in 1:length(webSite.id)) {
webSite.time[i] <- sum(recommandations[recommandations$webSite_id == webSite.id[i],]$time) * coeff
}
coeff <- coeff - 0.1
resultat <- matrix(NA, nrow = length(webSite.id), ncol = 2)
resultat[,1] <- webSite.id
resultat[,2] <- webSite.time
previousDay <- getPreviousDay(d)
nextDay <- getNextDay(d)
previousTimeSolt <- getPreviousTimeSolt(d, timeSolt.hourMin)
nextTimeSolt <- getNextTimeSolt(d, timeSolt.hourMin, timeSolt.hourMax)
for (i in 1:3) {
resultat <- mergeRecommandations(resultat, getLazyRecommandations(id, timeSolt.hourMin, timeSolt.hourMax, previousDay, coeff))
resultat <- mergeRecommandations(resultat, getLazyRecommandations(id, timeSolt.hourMin, timeSolt.hourMax, nextDay, coeff))
resultat <- mergeRecommandations(resultat, getLazyRecommandations(id, previousTimeSolt[2], previousTimeSolt[3], previousTimeSolt[1], coeff))
resultat <- mergeRecommandations(resultat, getLazyRecommandations(id, nextTimeSolt[2], nextTimeSolt[3], nextTimeSolt[1], coeff))
previousDay <- getPreviousDay(previousDay)
nextDay <- getNextDay(nextDay)
previousTimeSolt <- getPreviousTimeSolt(previousTimeSolt[1], previousTimeSolt[2])
nextTimeSolt <- getNextTimeSolt(nextTimeSolt[1], nextTimeSolt[2])
coeff <- coeff - 0.1
}
while (coeff > 0) {
resultat <- mergeRecommandations(resultat, getLazyRecommandations(id, previousTimeSolt[2], previousTimeSolt[3], previousTimeSolt[1], coeff))
resultat <- mergeRecommandations(resultat, getLazyRecommandations(id, nextTimeSolt[2], nextTimeSolt[3], nextTimeSolt[1], coeff))
previousTimeSolt <- getPreviousTimeSolt(previousTimeSolt[1], previousTimeSolt[2])
nextTimeSolt <- getNextTimeSolt(nextTimeSolt[1], nextTimeSolt[2])
coeff <- coeff - 0.1
}
resultat <- mergeRecommandations(resultat, getRecommandationsForLocalization(latitude, longitude, id))
resultat[,2] <- resultat[,2] / sum(resultat[,2])
return(resultat[order(resultat[,2], decreasing = TRUE),])
}
recommandations <- getRecommandations(user.id, hour, day)
i.data[recommandations[,1],]
